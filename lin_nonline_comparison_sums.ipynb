{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook to compare linear models with linear models based on nonlinear features\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as clr\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "# Initialize the random seed to ensure reproducibility of the results in the paper\n",
    "random.seed(42)\n",
    "np.random.seed(42) \n",
    "\n",
    "import pickle\n",
    "from jax import jacfwd\n",
    "import jax.numpy as jnp\n",
    "import copy\n",
    "# Import interact function from ipywidgets\n",
    "from ipywidgets import interact, fixed\n",
    "# Import float slider from ipywidgets\n",
    "from ipywidgets import FloatSlider, IntSlider, widgets\n",
    "\n",
    "import src.featlin\n",
    "from src.featlin import Featlin\n",
    "from src.featlin import jax_moment\n",
    "from src.helper import optimize_cv\n",
    "\n",
    "import src.basis as basis\n",
    "from src.basis import BasicsData\n",
    "\n",
    "plt.style.use('./styles/plots.mplstyle')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to generate data or load it from file\n",
    "# Load it from file to reproduce results from the paper\n",
    "# Otherwise, random noise will be different, leading to different results\n",
    "generate_data = 1\n",
    "\n",
    "# Setting this variable to 1 will save the generated data to file\n",
    "# And overwrite the data in the folder \n",
    "save_generated_data = 0\n",
    "\n",
    "remove_outliers = 1\n",
    "\n",
    "feature = 'sums'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generated\n"
     ]
    }
   ],
   "source": [
    "def construct_y_data(X, targetfun, per_range: list=None):\n",
    "    \"\"\"Construct responsese for a given target function\n",
    "    \"\"\"\n",
    "    if per_range is None:\n",
    "        per_range = [0, 1]\n",
    "\n",
    "    columns = X.shape[1]\n",
    "    low_ind = int(per_range[0]*columns)\n",
    "    high_ind = int(per_range[1]*columns)\n",
    "    # self.y = targetfun(self.X[:, low_ind:high_ind])\n",
    "\n",
    "    rows = X.shape[0]\n",
    "    y = np.zeros([rows])\n",
    "    for i in range(rows):\n",
    "        row_i = X[i, :]\n",
    "        y[i] = targetfun(row_i[low_ind:high_ind])\n",
    "    return y\n",
    "\n",
    "def add_wgn(y, snr_y=50):\n",
    "        \"\"\"Generates synthethic data to test the linearization methodology. \n",
    "\n",
    "        \"\"\"\n",
    "        # Add Gaussian noise to the measurements\n",
    "        # Snippet below partly copied/adapted/inspired by: \n",
    "        # https://stackoverflow.com/questions/14058340/adding-noise-to-a-signal-in-python\n",
    "        # Answer from Noel Evans, accessed: 18.05.2022, 15:37 CET\n",
    "        # Calculate signal power and convert to dB \n",
    "\n",
    "        for i, yi in enumerate(y): \n",
    "            sig_avg_watts = np.mean(yi**2)\n",
    "            sig_avg_db = 10 * np.log10(sig_avg_watts)\n",
    "            # Calculate noise according to [2] then convert to watts\n",
    "            noise_avg_db = sig_avg_db - snr_y\n",
    "            noise_avg_watts = 10 ** (noise_avg_db / 10)\n",
    "            # Generate an sample of white noise\n",
    "            mean_noise = 0\n",
    "            noise = np.random.normal(mean_noise, np.sqrt(noise_avg_watts), 1)\n",
    "            # Noise up the original signal\n",
    "            y[i] += noise\n",
    "\n",
    "        return y\n",
    "\n",
    "if generate_data:\n",
    "    # Load the LFP Dataset\n",
    "    lfp_df = pd.read_csv('./data/lfp_slim.csv', index_col=0)\n",
    "\n",
    "    X_lfp = np.array(lfp_df.iloc[:, 0:1000])\n",
    "    X_lfp = X_lfp[:, ::-1]\n",
    "    y_lfp_true = np.array(lfp_df.iloc[:, 1000])\n",
    "\n",
    "\n",
    "    X_lfp_train = np.array(X_lfp[lfp_df.iloc[:, 1002]==0, :])\n",
    "    y_lfp_train_true = np.log10(np.array(y_lfp_true[lfp_df.iloc[:, 1002]==0]))\n",
    "    X_lfp_test = np.array(X_lfp[lfp_df.iloc[:, 1002]==1, :])\n",
    "    y_lfp_test_true = np.log10(np.array(y_lfp_true[lfp_df.iloc[:, 1002]==1]))\n",
    "    X_lfp_test2 = np.array(X_lfp[lfp_df.iloc[:, 1002]==2, :])\n",
    "    y_lfp_test2_true = np.log10(np.array(y_lfp_true[lfp_df.iloc[:, 1002]==2]))\n",
    "\n",
    "    sums_function = lambda a : jnp.sum(a**2)\n",
    "    variance_function = lambda a : jnp.var(a)\n",
    "\n",
    "    y_train_sums = add_wgn(construct_y_data(X_lfp_train, sums_function), snr_y=40)\n",
    "    y_test_sums = add_wgn(construct_y_data(X_lfp_test, sums_function), snr_y=40)\n",
    "    y_test2_sums = add_wgn(construct_y_data(X_lfp_test2, sums_function), snr_y=40)\n",
    "\n",
    "    #y_train_sums = construct_y_data(X_lfp_train, sums_function)\n",
    "    #y_test_sums = construct_y_data(X_lfp_test, sums_function)\n",
    "    #y_test2_sums = construct_y_data(X_lfp_test2, sums_function)\n",
    "\n",
    "    y_train_var = add_wgn(construct_y_data(X_lfp_train, variance_function), snr_y=40)\n",
    "    y_test_var = add_wgn(construct_y_data(X_lfp_test, variance_function), snr_y=40)\n",
    "    y_test2_var = add_wgn(construct_y_data(X_lfp_test2, variance_function), snr_y=40)\n",
    "    #y_train_var = construct_y_data(X_lfp_train, variance_function)\n",
    "    #y_test_var = construct_y_data(X_lfp_test, variance_function)\n",
    "    #y_test2_var = construct_y_data(X_lfp_test2, variance_function)\n",
    "    print('Data generated')\n",
    "    # Pickle the data\n",
    "    if save_generated_data:\n",
    "        with open('./data/lfp_sums_nonlinex.pickle', 'wb') as f:\n",
    "            pickle.dump([X_lfp_train, y_train_sums, X_lfp_test, y_test_sums, X_lfp_test2, y_test2_sums], f)\n",
    "        with open('./data/lfp_variance_nonlinex.pickle', 'wb') as f:\n",
    "            pickle.dump([X_lfp_train, y_train_var, X_lfp_test, y_test_var, X_lfp_test2, y_test2_var], f)\n",
    "\n",
    "# Load the data\n",
    "if not generate_data:\n",
    "    with open('./data/lfp_sums_nonlinex.pickle', 'rb') as f:\n",
    "        X_lfp_train, y_train_sums, X_lfp_test, y_test_sums, X_lfp_test2, y_test2_sums = pickle.load(f)\n",
    "    \n",
    "    with open('./data/lfp_variance_nonlinex.pickle', 'rb') as f:\n",
    "        X_lfp_train, y_train_var, X_lfp_test, y_test_var, X_lfp_test2, y_test2_var = pickle.load(f)\n",
    "\n",
    "if feature == 'sums':\n",
    "    y_train = y_train_sums\n",
    "    y_test = y_test_sums\n",
    "    y_test2 = y_test2_sums\n",
    "elif feature == 'variance':\n",
    "    y_train = y_train_var\n",
    "    y_test = y_test_var\n",
    "    y_test2 = y_test2_var\n",
    "    \n",
    "x_lfp = np.linspace(2.0, 3.5, 1000)\n",
    "labels_lfp = {'xdata_label': 'Voltage (V)', 'ydata_label': r'$\\Delta \\mathbf{Q}_{100\\mathrm{-}10}$ (Ah)', 'row_label': 'Battery number'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the two nasty outliers\n",
    "if remove_outliers:\n",
    "    # Remove outlier Training\n",
    "    id_outlier = np.where(np.mean(X_lfp_train, axis=1)==np.min(np.mean(X_lfp_train, axis=1)))\n",
    "    X_lfp_train = np.delete(X_lfp_train, id_outlier, axis=0)\n",
    "    y_train = np.delete(y_train, id_outlier, axis=0)\n",
    "\n",
    "    # Remove outlier Test\n",
    "    for i in range(2):\n",
    "        id_outlier = np.where(np.mean(X_lfp_test, axis=1)==np.min(np.mean(X_lfp_test, axis=1)))\n",
    "        X_lfp_test = np.delete(X_lfp_test, id_outlier, axis=0)\n",
    "        y_test = np.delete(y_test, id_outlier, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting all data in a dictionary\n",
    "meanX = np.mean(X_lfp_train, axis=0)\n",
    "stdX = np.std(X_lfp_train, axis=0)\n",
    "meany = np.mean(y_train)\n",
    "\n",
    "X_dict = {\n",
    "    'train': X_lfp_train, 'test': X_lfp_test, 'test2': X_lfp_test2, 'x': x_lfp, \n",
    "    'train_': X_lfp_train-meanX, 'test_': X_lfp_test-meanX, 'test2_': X_lfp_test2-meanX,\n",
    "    'train_std_': (X_lfp_train-meanX)/stdX, 'test_std_': (X_lfp_test-meanX)/stdX, 'test2_std_': (X_lfp_test2-meanX)/stdX,\n",
    "    'mean': meanX, 'std': stdX}\n",
    "\n",
    "y_dict = {\n",
    "    'train': y_train, 'test': y_test, 'test2': y_test2,\n",
    "    'train_': y_train-meany, 'test_': y_test-meany, 'test2_': y_test2-meany,\n",
    "    'mean': meany}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature == 'sums':\n",
    "    x_train = np.sum(X_dict['train']**2, axis=1)\n",
    "    x_test = np.sum(X_dict['test']**2, axis=1)\n",
    "    x_test2 = np.sum(X_dict['test2']**2, axis=1)\n",
    "elif feature == 'variance':\n",
    "    x_train = np.var(X_dict['train'], axis=1)\n",
    "    x_test = np.var(X_dict['test'], axis=1)\n",
    "    x_test2 = np.var(X_dict['test2'], axis=1)\n",
    "\n",
    "# append the variance to the X matrix\n",
    "X_dict['train_feat'] = x_train\n",
    "X_dict['test_feat'] = x_test\n",
    "X_dict['test2_feat'] = x_test2\n",
    "X_dict['train_feat_'] = X_dict['train_feat']-np.mean(X_dict['train_feat'], axis=0)\n",
    "X_dict['test_feat_'] = X_dict['test_feat']-np.mean(X_dict['train_feat'], axis=0)\n",
    "X_dict['test2_feat_'] = X_dict['test2_feat']-np.mean(X_dict['train_feat'], axis=0)\n",
    "X_dict['train_feat_std_'] = X_dict['train_feat_']/np.std(X_dict['train_feat_'], axis=0)\n",
    "X_dict['test_feat_std_'] = X_dict['test_feat_']/np.std(X_dict['train_feat_'], axis=0)\n",
    "X_dict['test2_feat_std_'] = X_dict['test2_feat_']/np.std(X_dict['train_feat_'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run crossvalidation to estimate parameters.\n",
    "# 4 runs, two per model (std and non std dat)\n",
    "# Compare predictions where y is the cye life\n",
    "\n",
    "res_dict_rr_ = optimize_cv(X_dict['train_'], y_dict['train_'], max_comps=20, alpha_lim=[10e-7, 10e3], folds=10, nb_stds=1, \n",
    "        plot_components=False, std=False, min_distance_search=False, \n",
    "        featlin=None, algorithm='RR', plot=False)\n",
    "\n",
    "\n",
    "res_dict_pls_ = optimize_cv(X_dict['train_'], y_dict['train_'], max_comps=20, alpha_lim=[10e-5, 10e3], folds=10, nb_stds=1, \n",
    "        plot_components=False, std=False, min_distance_search=False, \n",
    "        featlin=None, algorithm='PLS', plot=False)\n",
    "\n",
    "\n",
    "res_dict_rr_std = optimize_cv(X_dict['train_std_'], y_dict['train_'], max_comps=20, alpha_lim=[10e-1, 10e2], folds=10, nb_stds=1, \n",
    "        plot_components=False, std=False, min_distance_search=False, \n",
    "        featlin=None, algorithm='RR', plot=False)\n",
    "\n",
    "res_dict_pls_std = optimize_cv(X_dict['train_std_'], y_dict['train_'], max_comps=20, alpha_lim=[10e-1, 10e2], folds=10, nb_stds=1, \n",
    "        plot_components=False, std=False, min_distance_search=False, \n",
    "        featlin=None, algorithm='PLS', plot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLS CV opt: 5\n",
      "PLS CV1sig: 3\n",
      "PLS CV opt std: 8\n",
      "PLS CV1sig std: 1\n",
      "RR CV opt: 0.0001\n",
      "RR CV1sig: 0.0007196856730011522\n",
      "RR CV1 opt std: 15.848931924611133\n",
      "RR CV1sig std: 138.94954943731375\n"
     ]
    }
   ],
   "source": [
    "print('PLS CV opt: ' + str(res_dict_pls_['cv_res']['rmse_min_param']))\n",
    "print('PLS CV1sig: ' + str(res_dict_pls_['cv_res']['rmse_std_min_param']))\n",
    "print('PLS CV opt std: ' + str(res_dict_pls_std['cv_res']['rmse_min_param']))\n",
    "print('PLS CV1sig std: ' + str(res_dict_pls_std['cv_res']['rmse_std_min_param']))\n",
    "\n",
    "print('RR CV opt: ' + str(res_dict_rr_['cv_res']['rmse_min_param']))\n",
    "print('RR CV1sig: ' + str(res_dict_rr_['cv_res']['rmse_std_min_param']))\n",
    "print('RR CV1 opt std: ' + str(res_dict_rr_std['cv_res']['rmse_min_param']))\n",
    "print('RR CV1sig std: ' + str(res_dict_rr_std['cv_res']['rmse_std_min_param']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting all models in a dictionary\n",
    "# Scale and intercept are set to false becasue I prefer to do it manually\n",
    "# This list is a bit long, but it is easier to keep track of the models this way for this comparison.\n",
    "models = {\n",
    "    'OLS': LinearRegression(fit_intercept=False),\n",
    "    'PLS_cv': PLSRegression(n_components=res_dict_pls_['cv_res']['rmse_min_param'], scale=False),\n",
    "    'PLS_cv1sig': PLSRegression(n_components=res_dict_pls_['cv_res']['rmse_std_min_param'], scale=False),\n",
    "    'PLS_cv_std': PLSRegression(n_components=res_dict_pls_std['cv_res']['rmse_min_param'], scale=False),\n",
    "    'PLS_cv1sig_std': PLSRegression(n_components=res_dict_pls_std['cv_res']['rmse_std_min_param'], scale=False),\n",
    "    'RR_cv': Ridge(alpha=res_dict_rr_['cv_res']['rmse_min_param'], fit_intercept=False),\n",
    "    'RR_cv1sig': Ridge(alpha=res_dict_rr_['cv_res']['rmse_std_min_param'], fit_intercept=False),\n",
    "    'RR_cv_std': Ridge(alpha=res_dict_rr_std['cv_res']['rmse_min_param'], fit_intercept=False),\n",
    "    'RR_cv1sig_std': Ridge(alpha=res_dict_rr_std['cv_res']['rmse_std_min_param'], fit_intercept=False)}\n",
    "\n",
    "\n",
    "# Making a pd dataframe to store the results\n",
    "results = pd.DataFrame(index=models.keys(), columns=['X', 'y', 'NRMSE Training', 'NRMSE Test', 'NRMSE Test 2', 'RMSE Training', 'RMSE Test', 'RMSE Test 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit all models that only depend on the raw data\n",
    "\n",
    "for key in models.keys():\n",
    "    if 'OLS' in key:\n",
    "        X_ = X_dict['train_feat_'].reshape(-1, 1)\n",
    "        X_test_ = X_dict['test_feat_'].reshape(-1, 1)\n",
    "        X_test2_ = X_dict['test2_feat_'].reshape(-1, 1)\n",
    "        X_tag = 'Sum of Squares'\n",
    "    else:\n",
    "        if key.endswith('std'):\n",
    "            X_ = X_dict['train_std_']\n",
    "            X_test_ = X_dict['test_std_']\n",
    "            X_test2_ = X_dict['test2_std_']\n",
    "            X_tag = 'Z-scored'\n",
    "        else:\n",
    "            X_ = X_dict['train_']\n",
    "            X_test_ = X_dict['test_']\n",
    "            X_test2_ = X_dict['test2_']\n",
    "            X_tag = 'Mean-centered'\n",
    "    y_ = y_dict['train_']\n",
    "    y_test_ = y_dict['test_']\n",
    "    y_test2_ = y_dict['test2_']\n",
    "    y = y_dict['train']\n",
    "    y_test = y_dict['test']\n",
    "    y_test2 = y_dict['test2']\n",
    "    y_tag = 'Sum of Squares, SNR=50'\n",
    "    \n",
    "    # Fit the model\n",
    "    models[key].fit(X_, y_)\n",
    "\n",
    "    # Predict the training data\n",
    "    y_pred = models[key].predict(X_)+y_dict['mean']\n",
    "    y_test_pred = models[key].predict(X_test_)+y_dict['mean']\n",
    "    y_test2_pred = models[key].predict(X_test2_)+y_dict['mean']\n",
    "    \n",
    "\n",
    "    # Calculate the MSE\n",
    "    mse_train = mean_squared_error(y, y_pred, squared=False)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "    mse_test2 = mean_squared_error(y_test2, y_test2_pred, squared=False)\n",
    "\n",
    "    # Calculate the NRMSE\n",
    "    # I am using the std of the training data to calculate the NRMSE    \n",
    "    nrmse_train = 100*mean_squared_error(y, y_pred, squared=False)/(np.max(y_)-np.min(y_))\n",
    "    nrmse_test = 100*mean_squared_error(y_test, y_test_pred, squared=False)/(np.max(y_)-np.min(y_))\n",
    "    nrmse_test2 = 100*mean_squared_error(y_test2, y_test2_pred, squared=False)/(np.max(y_)-np.min(y_))\n",
    "    \n",
    "    # Store the results\n",
    "    results.loc[key, 'Model'] = ''\n",
    "    results.loc[key, 'X'] = X_tag\n",
    "    results.loc[key, 'y'] = y_tag\n",
    "    results.loc[key, 'NRMSE Training'] = nrmse_train\n",
    "    results.loc[key, 'NRMSE Test'] = nrmse_test\n",
    "    results.loc[key, 'NRMSE Test 2'] = nrmse_test2\n",
    "    results.loc[key, 'RMSE Training'] = mse_train\n",
    "    results.loc[key, 'RMSE Test'] = mse_test\n",
    "    results.loc[key, 'RMSE Test 2'] = mse_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>NRMSE Training</th>\n",
       "      <th>NRMSE Test</th>\n",
       "      <th>NRMSE Test 2</th>\n",
       "      <th>RMSE Training</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>RMSE Test 2</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>Sum of Squares</td>\n",
       "      <td>Sum of Squares, SNR=50</td>\n",
       "      <td>0.359425</td>\n",
       "      <td>0.421122</td>\n",
       "      <td>0.200589</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>0.008656</td>\n",
       "      <td>0.004123</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS_cv</th>\n",
       "      <td>Mean-centered</td>\n",
       "      <td>Sum of Squares, SNR=50</td>\n",
       "      <td>3.156452</td>\n",
       "      <td>3.111199</td>\n",
       "      <td>4.769558</td>\n",
       "      <td>0.064879</td>\n",
       "      <td>0.063949</td>\n",
       "      <td>0.098036</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS_cv1sig</th>\n",
       "      <td>Mean-centered</td>\n",
       "      <td>Sum of Squares, SNR=50</td>\n",
       "      <td>3.610099</td>\n",
       "      <td>3.671289</td>\n",
       "      <td>4.830629</td>\n",
       "      <td>0.074204</td>\n",
       "      <td>0.075461</td>\n",
       "      <td>0.099291</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS_cv_std</th>\n",
       "      <td>Z-scored</td>\n",
       "      <td>Sum of Squares, SNR=50</td>\n",
       "      <td>2.390064</td>\n",
       "      <td>3.003339</td>\n",
       "      <td>4.14236</td>\n",
       "      <td>0.049126</td>\n",
       "      <td>0.061732</td>\n",
       "      <td>0.085144</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS_cv1sig_std</th>\n",
       "      <td>Z-scored</td>\n",
       "      <td>Sum of Squares, SNR=50</td>\n",
       "      <td>5.103634</td>\n",
       "      <td>4.719957</td>\n",
       "      <td>5.20599</td>\n",
       "      <td>0.104902</td>\n",
       "      <td>0.097016</td>\n",
       "      <td>0.107006</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             X                       y NRMSE Training  \\\n",
       "OLS             Sum of Squares  Sum of Squares, SNR=50       0.359425   \n",
       "PLS_cv           Mean-centered  Sum of Squares, SNR=50       3.156452   \n",
       "PLS_cv1sig       Mean-centered  Sum of Squares, SNR=50       3.610099   \n",
       "PLS_cv_std            Z-scored  Sum of Squares, SNR=50       2.390064   \n",
       "PLS_cv1sig_std        Z-scored  Sum of Squares, SNR=50       5.103634   \n",
       "\n",
       "               NRMSE Test NRMSE Test 2 RMSE Training RMSE Test RMSE Test 2  \\\n",
       "OLS              0.421122     0.200589      0.007388  0.008656    0.004123   \n",
       "PLS_cv           3.111199     4.769558      0.064879  0.063949    0.098036   \n",
       "PLS_cv1sig       3.671289     4.830629      0.074204  0.075461    0.099291   \n",
       "PLS_cv_std       3.003339      4.14236      0.049126  0.061732    0.085144   \n",
       "PLS_cv1sig_std   4.719957      5.20599      0.104902  0.097016    0.107006   \n",
       "\n",
       "               Model  \n",
       "OLS                   \n",
       "PLS_cv                \n",
       "PLS_cv1sig            \n",
       "PLS_cv_std            \n",
       "PLS_cv1sig_std        "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ht/42wc4pfd5y78cjfbdt_5qljr0000gn/T/ipykernel_76785/1068712045.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_df.iloc[:5, :].to_latex('reg-results.tex', index=True)\n"
     ]
    }
   ],
   "source": [
    "latex_df = copy.deepcopy(results.iloc[:5, :5])\n",
    "if remove_outliers:\n",
    "    latex_df.iloc[:5, :].to_latex('reg-results_outlier_rem.tex', index=True)\n",
    "else:\n",
    "    latex_df.iloc[:5, :].to_latex('reg-results.tex', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model struggles to learn the dependencies when outliers are removed, in the case of this ideal feature. \n",
    "# For the cycle life reponse, jthings are more complex, since you cannot simply state that features will make everyhthign better (but help eioth outliers) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35581e9e5c93b147a4fdfb3f5a6931fd10b2fba7c5647a16d9992458a85cc163"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
