coeff_fused_lasso = coef(fl, lambda = lambda_val, exact = T)
plot(x_lfp, coeff_fused_lasso$beta, type = "l")
# Check the predictions. (put the prediction stuff in a function for easy calling!)
# Interesting coefficients!
y_pred <- predict(fl, lambda = lambda_val, Xnew = X_train_)$fit
y_pred_test1 <-
predict(fl, lambda = lambda_val, Xnew = X_test1_)$fit
y_pred_test2 <-
predict(fl, lambda = lambda_val, Xnew = X_test2_)$fit
plot_predictions_lfp(y_train,
y_pred,
y_test1,
y_pred_test1,
y_test2,
y_pred_test2,
y_train_list)
cvfit$lambda.min
cvfit$lambda.1se
# REGRESSION SECTION
# Run regression with glmnet (alpha = 0 is ridge regression!)
lambda_seq <- logseq(10 ^ -6, 1, n = 1000)
cvfit <-
cv.glmnet(
X_train_,
y_train_,
n_folds = 40,
alpha = 0,
lambda = lambda_seq,
standardize = F,
)
cvfit$lambda.1se
cvfit$lambda.min
# REGRESSION SECTION
# Run regression with glmnet (alpha = 0 is ridge regression!)
lambda_seq <- logseq(10 ^ -8, 0.1, n = 1000)
cvfit <-
cv.glmnet(
X_train_,
y_train_,
n_folds = 10,
alpha = 0,
lambda = lambda_seq,
standardize = F,
)
plot(cvfit)
cvfit$lambda.min
cvfit$lambda.min
cvfit$lambda.1se
# Run CV on the elastic net:
# Code Snippets from: https://rpubs.com/jmkelly91/881590
models <- list()
for (i in 0:20) {
name <- paste0("alpha", i / 20)
models[[name]] <-
cv.glmnet(
X_train_,
y_train_,
n_folds = 10,
alpha = i/20,
lambda = lambda_seq,
standardize = F,
)
}
cvfit$cmv
min(cvfit$cmv)
min(cvfit$cvm)
which(min(cvfit$cvm))
which(cvfit$cvm)
which(min(cvfit$cvm) == cvfit$cvm)
lambda_seq[545]
cvfit$lambda.min
lambda_seq[546]
lambda_seq[544]
lambda_seq[-545]
lambda_seq[545]
which(min(cvfit$cvm) == cvfit$cvm)
cvfit$lambda.min
cvfit$lambda[545]
for (i in 0:20) {
name <- paste0("alpha", i/20)
# min_cvm_id <- which(min(models[[name]]$cvm) == models[[name]]$cvm)
mse <- min(models[[name]]$cvm)
lambda_min <- models[[name]]$lambda.min
lambda_1se <- models[[name]]$lambda.1se
## Store the results
temp <- data.frame(alpha=i/20, min_mse=mse, lambda_min=lambda_min, lambda_1se=lambda_1se, name=name)
results <- rbind(results, temp)
}
for (i in 0:20) {
name <- paste0("alpha", i / 20)
models[[name]] <-
cv.glmnet(
X_train_,
y_train_,
n_folds = 10,
alpha = i/20,
lambda = lambda_seq,
standardize = F,
)
# min_cvm_id <- which(min(models[[name]]$cvm) == models[[name]]$cvm)
mse <- min(models[[name]]$cvm)
lambda_min <- models[[name]]$lambda.min
lambda_1se <- models[[name]]$lambda.1se
## Store the results
temp <- data.frame(alpha=i/20, min_mse=mse, lambda_min=lambda_min, lambda_1se=lambda_1se, name=name)
results <- rbind(results, temp)
}
results
# Run CV on the elastic net:
# Code Snippets from: https://rpubs.com/jmkelly91/881590
models <- list()
results <- data.frame()
for (i in 0:20) {
name <- paste0("alpha", i / 20)
models[[name]] <-
cv.glmnet(
X_train_,
y_train_,
n_folds = 10,
alpha = i/20,
lambda = lambda_seq,
standardize = F,
)
# min_cvm_id <- which(min(models[[name]]$cvm) == models[[name]]$cvm)
mse <- min(models[[name]]$cvm)
lambda_min <- models[[name]]$lambda.min
lambda_1se <- models[[name]]$lambda.1se
## Store the results
temp <- data.frame(alpha=i/20, min_mse=mse, lambda_min=lambda_min, lambda_1se=lambda_1se, name=name)
results <- rbind(results, temp)
}
disp(name)
for (i in 0:20) {
name <- paste0("alpha", i / 20)
disp(name)
models[[name]] <-
cv.glmnet(
X_train_,
y_train_,
n_folds = 10,
alpha = i/20,
lambda = lambda_seq,
standardize = F,
)
# min_cvm_id <- which(min(models[[name]]$cvm) == models[[name]]$cvm)
mse <- min(models[[name]]$cvm)
lambda_min <- models[[name]]$lambda.min
lambda_1se <- models[[name]]$lambda.1se
## Store the results
temp <- data.frame(alpha=i/20, min_mse=mse, lambda_min=lambda_min, lambda_1se=lambda_1se, name=name)
results <- rbind(results, temp)
}
results
results_best <- results[which(min(results$min_mse)==results$min_mse)]
results_best <- results[which(min(results$min_mse)==results$min_mse),]
results-best
results_best
results_best$name
best_id <- which(min(results$min_mse)==results$min_mse)
results_best <- results[best_id,]
## CLEAN UP
rm(list = ls())
tryCatch(
p_unload(all),
error = function(e) {
print("Skip clearing plots, probably no addons!")
}
)
tryCatch(
dev.off(),
error = function(e) {
print("Skip clearing plots, probably no plots!")
}
)
cat("\014")
## LOADING
pacman::p_load(pacman,
MASS,
bayesreg,
glmnet,
rio,
ggplot2,
pracma,
genlasso,
Matrix,
resample)
path_base <-
"~/Documents/PhD/02Research/01Papers/03Nullspace/HDFeat/"
source(paste(path_base, "regression_in_R/utils.R", sep = ""))
## CLEAN UP
rm(list = ls())
tryCatch(
p_unload(all),
error = function(e) {
print("Skip clearing plots, probably no addons!")
}
)
tryCatch(
dev.off(),
error = function(e) {
print("Skip clearing plots, probably no plots!")
}
)
cat("\014")
## CLEAN UP
rm(list = ls())
tryCatch(
p_unload(all),
error = function(e) {
print("Skip clearing plots, probably no addons!")
}
)
tryCatch(
dev.off(),
error = function(e) {
print("Skip clearing plots, probably no plots!")
}
)
cat("\014")
## LOADING
pacman::p_load(pacman,
MASS,
bayesreg,
glmnet,
rio,
ggplot2,
pracma,
genlasso,
Matrix,
resample)
path_base <-
"~/Documents/PhD/02Research/01Papers/03Nullspace/HDFeat/"
source(paste(path_base, "regression_in_R/utils.R", sep = ""))
## Load Data
path <- paste(path_base, "data/lfp_slim.csv", sep = "")
lfp_data = import(path)
## Construct Data Matrices
train_id <- lfp_data[, 1004] == 0
test1_id <- lfp_data[, 1004] == 1
test1_id[43] <- F # Removing the shortest lived outlier battery!
test2_id <- lfp_data[, 1004] == 2
X <- unname(as.matrix(rev(lfp_data[, 2:1001])))
X_list <- centerXtrain(X)
X_ = X_list$X_
X_train <- X[train_id, ]
X_test1 <- X[test1_id, ]
X_test2 <- X[test2_id, ]
X_train_list <- centerXtrain(X_train)
X_train_ <- X_train_list$X_
X_test1_ <- centerXtest(X_test1, X_train_list)
X_test2_ <- centerXtest(X_test2, X_train_list)
y <-  lfp_data[, 1002]
y_train <- log(unname(as.matrix(y[train_id])))
y_test1 <- log(unname(as.matrix(y[test1_id])))
y_test2 <- log(unname(as.matrix(y[test2_id])))
y_train_list <- standardize_y_train(y_train)
y_train_ <- y_train_list$y_std
y_train_mean = rowMeans(X_train)
y_train_mean_ <- y_train_mean - mean(y_train_mean)
x_lfp <-  seq(2, 3.5, length.out = 1000)
## Data Visualization
matplot(
t(X),
type = "l",
ylab = "DeltaQ (V)",
xlab = "Voltage (V)",
main = "LFP Data Set"
)
matplot(
t(X_train_),
type = "l",
ylab = "DeltaQ (V)",
xlab = "Voltage (V)",
main = "LFP Data Set"
)
# REGRESSION SECTION
# Run regression with glmnet (alpha = 0 is ridge regression!)
lambda_seq <- logseq(10 ^ -8, 0.1, n = 1000)
cvfit <-
cv.glmnet(
X_train_,
y_train_,
n_folds = 10,
alpha = 0,
lambda = lambda_seq,
standardize = F,
)
plot(cvfit)
cvfit$lambda.min
cvfit$lambda.1se
plot(
x_lfp,
coef(cvfit, s = "lambda.1se", excact = T)[2:1001,],
type = 'l',
ylab = "",
xlab = ""
)
# Calculate stats on tests sets
y_pred <- predict(cvfit, X_train_, s = cvfit$lambda.min)
y_pred_test1 <- predict(cvfit, X_test1_, s = cvfit$lambda.min)
y_pred_test2 <- predict(cvfit, X_test2_, s = cvfit$lambda.min)
plot_predictions_lfp(y_train,
y_pred,
y_test1,
y_pred_test1,
y_test2,
y_pred_test2,
y_train_list)
# Calculate stats on tests sets
# 1 Se might yield lower results also because of the impacts of the outlier.
# Aka might build a model that will be more robust to this kind of data.
y_pred <- predict(cvfit, X_train_, s = cvfit$lambda.1se)
y_pred_test1 <- predict(cvfit, X_test1_, s = cvfit$lambda.1se)
y_pred_test2 <- predict(cvfit, X_test2_, s = cvfit$lambda.1se)
plot_predictions_lfp(y_train,
y_pred,
y_test1,
y_pred_test1,
y_test2,
y_pred_test2,
y_train_list)
# Run CV on the elastic net:
# Code Snippets from: https://rpubs.com/jmkelly91/881590
models <- list()
results <- data.frame()
for (i in 0:20) {
name <- paste0("alpha", i / 20)
disp(name)
models[[name]] <-
cv.glmnet(
X_train_,
y_train_,
n_folds = 10,
alpha = i/20,
lambda = lambda_seq,
standardize = F,
)
# min_cvm_id <- which(min(models[[name]]$cvm) == models[[name]]$cvm)
mse <- min(models[[name]]$cvm)
lambda_min <- models[[name]]$lambda.min
lambda_1se <- models[[name]]$lambda.1se
## Store the results
temp <- data.frame(alpha=i/20, min_mse=mse, lambda_min=lambda_min, lambda_1se=lambda_1se, name=name)
results <- rbind(results, temp)
}
best_id <- which(min(results$min_mse)==results$min_mse)
results_best <- results[best_id,]
plot(
x_lfp,
coef(models[[best_id]], lambda=results_best$lambda.1se, alpha=results_best$alpha, excact = T)[2:1001,],
type = 'l',
ylab = "",
xlab = ""
)
best_id
a.isnull
a.isnull()
a.isNULL
a = NULL
a.isNULL
a.isNULL
a.isnull
a.isnull()
a.isNULL()
a.is.Null
is.Null(a)
a
a.is.NULL()
is.null(a)
## LOADING
pacman::p_load(pacman,
MASS,
bayesreg,
glmnet,
rio,
ggplot2,
pracma,
genlasso,
Matrix,
resample)
path_base <-
"~/Documents/PhD/02Research/01Papers/03Nullspace/HDFeat/"
source(paste(path_base, "regression_in_R/utils.R", sep = ""))
# Calculate stats on tests sets
predict_plot_lfp(cvfit,
lambda_val = cvfit$lambda.min X_train_,
# Calculate stats on tests sets
predict_plot_lfp(cvfit,
lambda_val = cvfit$lambda.min,
X_train_,
X_test1_,
X_test2_,
y_train_list)
## LOADING
pacman::p_load(pacman,
MASS,
bayesreg,
glmnet,
rio,
ggplot2,
pracma,
genlasso,
Matrix,
resample)
path_base <-
"~/Documents/PhD/02Research/01Papers/03Nullspace/HDFeat/"
source(paste(path_base, "regression_in_R/utils.R", sep = ""))
# Calculate stats on tests sets
predict_plot_lfp(cvfit,
lambda_val = cvfit$lambda.min,
X_train_,
X_test1_,
X_test2_,
y_train_list,
model="cvfit")
source(paste(path_base, "regression_in_R/utils.R", sep = ""))
# Calculate stats on tests sets
predict_plot_lfp(cvfit,
lambda_val = cvfit$lambda.min,
X_train_,
X_test1_,
X_test2_,
y_train_list,
model="cvfit")
# Calculate stats on tests sets
predict_plot_lfp(cvfit,
lambda_val = cvfit$lambda.min,
X_train_,
X_test1_,
X_test2_,
y_train_list,
model="cvfit")
source(paste(path_base, "regression_in_R/utils.R", sep = ""))
# Calculate stats on tests sets
predict_plot_lfp(cvfit,
lambda_val = cvfit$lambda.min,
X_train_,
X_test1_,
X_test2_,
y_train_list,
model="cvfit")
y_pred <- predict(cvfit, X_train_, s = cvfit$lambda.min)
y_pred_test1 <- predict(cvfit, X_test1_, s = cvfit$lambda.min)
y_pred_test2 <- predict(cvfit, X_test2_, s = cvfit$lambda.min)
plot_predictions_lfp(y_train,
y_pred,
y_test1,
y_pred_test1,
y_test2,
y_pred_test2,
y_train_list)
## CLEAN UP
rm(list = ls())
tryCatch(
p_unload(all),
error = function(e) {
print("Skip clearing plots, probably no addons!")
}
)
tryCatch(
dev.off(),
error = function(e) {
print("Skip clearing plots, probably no plots!")
}
)
cat("\014")
## LOADING
pacman::p_load(pacman,
MASS,
bayesreg,
glmnet,
rio,
ggplot2,
pracma,
genlasso,
Matrix,
resample)
path_base <-
"~/Documents/PhD/02Research/01Papers/03Nullspace/HDFeat/"
source(paste(path_base, "regression_in_R/utils.R", sep = ""))
## Load Data
path <- paste(path_base, "data/lfp_slim.csv", sep = "")
lfp_data = import(path)
## Construct Data Matrices
train_id <- lfp_data[, 1004] == 0
test1_id <- lfp_data[, 1004] == 1
## CLEAN UP
rm(list = ls())
tryCatch(
p_unload(all),
error = function(e) {
print("Skip clearing plots, probably no addons!")
}
)
tryCatch(
dev.off(),
error = function(e) {
print("Skip clearing plots, probably no plots!")
}
)
cat("\014")
## LOADING
pacman::p_load(pacman,
MASS,
bayesreg,
glmnet,
rio,
ggplot2,
pracma,
genlasso,
Matrix,
resample)
