{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as clr\n",
    "import random\n",
    "# Initialize the random seed to ensure reproducibility of the results in the paper\n",
    "random.seed(10)\n",
    "import jax.numpy as jnp\n",
    "from src.featlin import Featlin\n",
    "from src.featlin import jax_moment\n",
    "from src.basis import BasicsData\n",
    "\n",
    "plt.style.use('./styles/plots.mplstyle')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plots = 0\n",
    "save_path = './results/Linearization/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colorblind safe palette from: https://gka.github.io/palettes/#/26|s|00429d,96ffea,ffffe0|ffffe0,ff005e,93003a|1|1 \n",
    "# IBM Colors: https://www.ibm.com/design/language/color/\n",
    "# https://lospec.com/palette-list/ibm-color-blind-safe\n",
    "\n",
    "colors = ['#332bb3', '#4a31b5', '#5d37b6', '#6d3db7', '#7c43b7', '#8a49b6', '#964fb5', '#a256b3', '#ad5db1', '#b764b0', '#c16cae', '#ca75ad', '#d27eac', '#d989ab', '#e094aa', '#e7a1ab', '#ecafac', '#f0beae', '#f4cfb0', '#f6e1b4']\n",
    "colors_IBM = ['#648fff', '#785ef0', '#dc267f', '#fe6100', '#ffb000',  '#000000']\n",
    "cmap_ = clr.LinearSegmentedColormap.from_list('Blue-light cb-safe', colors, N=256)\n",
    "cmap = clr.LinearSegmentedColormap.from_list('Blue-light cb-IBM', colors_IBM[:-1], N=256)\n",
    "color_list = [colors_IBM[0], colors_IBM[2], colors_IBM[3], colors_IBM[4], colors_IBM[5]]\n",
    "marker_list = ['s', 'o', 'D', 'P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LFP Dataset\n",
    "lfp_df = pd.read_csv('./data/lfp_slim.csv', index_col=0)\n",
    "\n",
    "X_lfp = np.array(lfp_df.iloc[:, 0:1000])\n",
    "X_lfp = X_lfp[:, ::-1]\n",
    "y_lfp_true = np.array(lfp_df.iloc[:, 1000])\n",
    "x_lfp = np.linspace(2.0, 3.5, 1000)\n",
    "\n",
    "X_lfp_train = np.array(X_lfp[lfp_df.iloc[:, 1002]==0, :])\n",
    "y_lfp_train_true = np.array(y_lfp_true[lfp_df.iloc[:, 1002]==0])\n",
    "X_lfp_test = np.array(X_lfp[lfp_df.iloc[:, 1002]==1, :])\n",
    "y_lfp_test_true = np.array(y_lfp_true[lfp_df.iloc[:, 1002]==1])\n",
    "X_lfp_test2 = np.array(X_lfp[lfp_df.iloc[:, 1002]==2, :])\n",
    "y_lfp_test2_true = np.array(y_lfp_true[lfp_df.iloc[:, 1002]==2])\n",
    "\n",
    "labels_lfp = {'xdata_label': 'Voltage (V)', 'ydata_label': r'$\\Delta \\mathbf{Q}_{100\\mathrm{-}10}$ (Ah)', 'row_label': 'Battery number'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outlier \n",
    "id_outlier = np.where(np.mean(X_lfp_train, axis=1)==np.min(np.mean(X_lfp_train, axis=1)))\n",
    "X_lfp_train = np.delete(X_lfp_train, id_outlier, axis=0)\n",
    "y_lfp_train_true = np.delete(y_lfp_train_true, id_outlier, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinus_transformation(X: np.ndarray, a=0.07) -> np.ndarray:\n",
    "    Y = jnp.sin((2*jnp.pi/a) * X)\n",
    "    if len(Y.shape) == 1:\n",
    "        y = jnp.sum(Y)\n",
    "    else:\n",
    "        y = jnp.sum(Y, axis=1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True underlying relationship between the measurements and some quantity we ewould like to recover/predict from measurements\n",
    "\n",
    "# JAX numpy wrapper target function  to allow for autodifferentiation\n",
    "fun_targetj = [\n",
    "    lambda x : jnp.mean(x),\n",
    "    lambda x: sinus_transformation(x, a=0.06), \n",
    "    lambda x : jnp.sum(x**2),\n",
    "    lambda x : jnp.var(x),\n",
    "    lambda x: jax_moment(x,3)/((jax_moment(x,2))**(3/2)),\n",
    "    lambda x: jax_moment(x,4)/(jax_moment(x,2)**2)-3\n",
    "    ]\n",
    "\n",
    "fun_target_names = [\n",
    "    'Sum',\n",
    "    'Sinus',\n",
    "    'Sum of Squares',\n",
    "    'Variance', \n",
    "    'Skewness',\n",
    "    'Kurtosis',\n",
    "    ]\n",
    "    \n",
    "feat_fun_dict = {fun_target_names[i] : fun_targetj[i] for i in range(len(fun_targetj))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate BasicsData class objects\n",
    "# Different examples, only the following are used in this notebook \n",
    "# 'Sum' : Simple illustration with PLS\n",
    "# 'Sinus': Using RR \n",
    "# 'Sum of Squares': Using RR and std \n",
    "# 'Variance': Using RR and std\n",
    "# --> 6 Case studies\n",
    "\n",
    "# Mean\n",
    "lfp_mean = BasicsData(X=X_lfp_train, x=x_lfp, y=None) \n",
    "lfp_mean = lfp_mean.construct_y_data(fun_targetj[0]).add_wgn(add_noise_X=False, add_noise_y=True, snr_y=50)\n",
    "\n",
    "# Sum Squares\n",
    "lfp_sums = BasicsData(X=X_lfp_train, x=x_lfp, y=None) \n",
    "lfp_sums = lfp_sums.construct_y_data(fun_targetj[1]).add_wgn(add_noise_X=False, add_noise_y=True, snr_y=50)\n",
    "\n",
    "# Sinus\n",
    "lfp_sin = BasicsData(X=X_lfp_train, x=x_lfp, y=None) \n",
    "lfp_sin = lfp_sin.construct_y_data(fun_targetj[2]).add_wgn(add_noise_X=False, add_noise_y=True, snr_y=50)\n",
    "\n",
    "# Variance\n",
    "lfp_var = BasicsData(X=X_lfp_train, x=x_lfp, y=None) \n",
    "lfp_var = lfp_var.construct_y_data(fun_targetj[3]).add_wgn(add_noise_X=False, add_noise_y=True, snr_y=50)\n",
    "\n",
    "# Skew\n",
    "lfp_skew = BasicsData(X=X_lfp_train, x=x_lfp, y=None) \n",
    "lfp_lfp_skewvar = lfp_skew.construct_y_data(fun_targetj[4]).add_wgn(add_noise_X=False, add_noise_y=True, snr_y=50)\n",
    "\n",
    "# Kurt\n",
    "lfp_kurt = BasicsData(X=X_lfp_train, x=x_lfp, y=None) \n",
    "lfp_kurt = lfp_kurt.construct_y_data(fun_targetj[5]).add_wgn(add_noise_X=False, add_noise_y=True, snr_y=50)\n",
    "\n",
    "# Log Cycle Life\n",
    "lfp_lcl = BasicsData(X=X_lfp_train, x=x_lfp, y=np.log(y_lfp_train_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Sum' : Simple illustration with PLS\n",
    "# Simple illustration inc ase model and ground truth are linear\n",
    "lfp_meangt = Featlin(data_obj=lfp_mean, feat_funcs=feat_fun_dict)\n",
    "\n",
    "fig_props = {'save':False, 'ax0_xlabel':'Voltage (V)', 'save_path':'./results/MeanGT',\n",
    "             'multiple_fig':False}\n",
    "\n",
    "lfp_meangt = lfp_meangt.analyze_all_features(\n",
    "    opt_cv={'active':False, 'model': []}, \n",
    "    opt_dist={'active':True, 'model': ['PLS']},\n",
    "    fig_props=fig_props, max_nrmse=0.1, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Sinus': Using RR \n",
    "lfp_singt = Featlin(data_obj=lfp_sin, feat_funcs=feat_fun_dict)\n",
    "\n",
    "fig_props = {'save':False, 'ax0_xlabel':'Voltage (V)', 'save_path':'./results/MeanGT',\n",
    "             'multiple_fig':False}\n",
    "\n",
    "lfp_meangt = lfp_meangt.analyze_all_features(\n",
    "    opt_cv={'active':False, 'model': []}, \n",
    "    opt_dist={'active':True, 'model': ['RR']},\n",
    "    fig_props=fig_props, max_nrmse=0.1, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Sum of Squares': Using RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Sum of Squares': Using RR and std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Variance': Using RR\n",
    "lfp_var_gt = Featlin(data_obj=lfp_var, feat_funcs=feat_fun_dict)\n",
    "\n",
    "fig_props = {'save':True, 'ax0_xlabel':'Voltage (V)', 'save_path':'./results/VarianceRR', 'response':'',\n",
    "            'multiple_fig':False}\n",
    "\n",
    "# Run the tests\n",
    "lfp_var_gt = lfp_var_gt.analyze_all_features(\n",
    "    opt_cv={'active':True, 'model': []}, \n",
    "    opt_dist={'active':True, 'model': ['RR']}, \n",
    "    fig_props = fig_props, max_nrmse=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Variance': Using PLS\n",
    "fig_props = {'save':True, 'ax0_xlabel':'Voltage (V)', 'save_path':'./results/VariancePLS', 'response':'',\n",
    "             'multiple_fig':False, 'response':'Groundtruth Response: Variance'}\n",
    "\n",
    "lfp_var_gt = Featlin(data_obj=lfp_var, feat_funcs=feat_fun_dict)\n",
    "\n",
    "# Run the tests\n",
    "lfp_var_gt = lfp_var_gt.analyze_all_features(\n",
    "    opt_cv={'active':True, 'model': []}, \n",
    "    opt_dist={'active':True, 'model': ['PLS']}, \n",
    "    fig_props = fig_props, max_nrmse=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Variance': Using RR and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Cycle Life\n",
    "fig_props = {'save':False, 'ax0_xlabel':'Voltage (V)', 'save_path':'./results/LCL_PLS', 'response':'',\n",
    "            'multiple_fig':False}\n",
    "\n",
    "fl_lfp_lcl = Featlin(data_obj=lfp_lcl, feat_funcs=feat_fun_dict)\n",
    "\n",
    "# Run the tests\n",
    "fl_lfp_lcl = fl_lfp_lcl.analyze_all_features(\n",
    "    opt_cv={'active':True, 'model': []}, \n",
    "    opt_dist={'active':True, 'model': ['RR']}, \n",
    "    fig_props = fig_props, max_nrmse=0.05)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35581e9e5c93b147a4fdfb3f5a6931fd10b2fba7c5647a16d9992458a85cc163"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
